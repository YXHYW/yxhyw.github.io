<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/机器学习/决策树" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">决策树 | 锄田</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://life.rainux.cn/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://life.rainux.cn/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://life.rainux.cn/docs/AI/机器学习/决策树"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="决策树 | 锄田"><meta data-rh="true" name="description" content="十大数据挖掘算法之决策树"><meta data-rh="true" property="og:description" content="十大数据挖掘算法之决策树"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://life.rainux.cn/docs/AI/机器学习/决策树"><link data-rh="true" rel="alternate" href="https://life.rainux.cn/docs/AI/机器学习/决策树" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://life.rainux.cn/docs/AI/机器学习/决策树" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="锄田 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="锄田 Atom Feed">




<link rel="stylesheet" href="/katex/katex.min.css"><link rel="stylesheet" href="/assets/css/styles.73acbba0.css">
<script src="/assets/js/runtime~main.fc2682f6.js" defer="defer"></script>
<script src="/assets/js/main.3cbc87c8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">花酒锄作田</b></a><a class="navbar__item navbar__link" href="/docs/category/fastapi">Python</a><a class="navbar__item navbar__link" href="/docs/category/gin">Go</a><a class="navbar__item navbar__link" href="/docs/category/postgresql">Database</a><a class="navbar__item navbar__link" href="/docs/category/kubernetes">Operation</a><a class="navbar__item navbar__link" href="/docs/category/数据结构">Algorithm</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/category/机器学习">AI</a><a class="navbar__item navbar__link" href="/docs/category/未分类">ReadNotes</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/about">About</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/category/机器学习">机器学习</a><button aria-label="折叠侧边栏分类 &#x27;机器学习&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AI/机器学习/apriori">apriori</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/AI/机器学习/决策树">决策树</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AI/机器学习/朴素贝叶斯">朴素贝叶斯</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/AI/机器学习/逻辑回归">逻辑回归</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">决策树</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>决策树</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="一什么是决策树">一、什么是决策树<a href="#一什么是决策树" class="hash-link" aria-label="一、什么是决策树的直接链接" title="一、什么是决策树的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="相关名词">相关名词<a href="#相关名词" class="hash-link" aria-label="相关名词的直接链接" title="相关名词的直接链接">​</a></h3>
<ul>
<li>信息熵</li>
<li>信息增益和信息增益率</li>
<li>剪枝、预剪枝和后剪枝</li>
<li>过拟合</li>
<li>根节点和叶节点
（关于这些名词涉及的具体算法本文不会多谈，详情请参阅周志华先生的《机器学习》）</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="11-决策树简介">1.1 决策树简介<a href="#11-决策树简介" class="hash-link" aria-label="1.1 决策树简介的直接链接" title="1.1 决策树简介的直接链接">​</a></h3>
<p>决策树（decision tree）是一类常见的机器学习方法。一般的，一棵决策树包含一个根节点，若干个内部结点和若干个叶节点；叶节点对应决策结果，其他节点则对应一个属性测试；每个结点包含样本集合根据属性测试的结果被划分到子结点中；根节点包含样本全集。决策树学习的目的是为了产生一颗泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的“分而治之”的策略。（摘自周志华的《机器学习》）</p>
<p>决策树可分为分类决策树和回归决策树，分类决策树有ID3决策树和C4.5决策树，回归决策树有CART决策树，其中C4.5和CART属于十大数据挖掘算法之二。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="12-优缺点">1.2 优缺点<a href="#12-优缺点" class="hash-link" aria-label="1.2 优缺点的直接链接" title="1.2 优缺点的直接链接">​</a></h3>
<ul>
<li>优点：计算复杂度不高，分类规则易于理解，准确度较高；</li>
<li>缺点：在构造树的过程中需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效，另外可能会产生过拟合的问题。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="二如何构造一个决策树">二、如何构造一个决策树<a href="#二如何构造一个决策树" class="hash-link" aria-label="二、如何构造一个决策树的直接链接" title="二、如何构造一个决策树的直接链接">​</a></h2>
<p>在谈如何构造决策树之前，我们需要先简单了解一下信息熵、信息增益和信息增益率。</p>
<p>信息熵指的是信息混乱程度，熵越大，信息混乱程度越高，纯度越低。比如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">A = [1, 2, 3, 4, 5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">5</span><span class="mclose">]</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">B=[1, 1, 1, 1, 2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">2</span><span class="mclose">]</span></span></span></span>，A的熵就比较高，B的熵就比较低。信息熵的计算公式如下：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H = -\sum_{i=0}^{n}p(x_i)log_2 (p(x_i))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.9291em;vertical-align:-1.2777em"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span>
<p>对A进行计算，假设每个值的取值概率为0.2，则A的信息熵为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>∗</mo><mo stretchy="false">(</mo><mn>0.2</mn><mo>∗</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mn>0.2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mn>2.3219</mn></mrow><annotation encoding="application/x-tex">5 *(0.2 * log_2(0.2))=2.3219</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0.2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">0.2</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2.3219</span></span></span></span>，而B的信息熵是1.49446。</p>
<p>信息增益指的是经过一个决策结点信息熵的变化量，信息增益越大，纯度提升越大。</p>
<p>不同于ID3使用信息增益，C4.5使用信息增益率，避免了用信息增益选择属性时偏向取值多的属性的问题。信息增益率的公式如下，其中D为信息熵。</p>
<p>构造决策树的一个要点就是如何选择结点，我们需要使用信息增益最大的结点。</p>
<p>使用决策树的基本想法是随着树深度的增加，节点的熵迅速的降低。熵降低速度越快越好，这样我们有望得到一个高度最矮的决策树。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="三剪枝">三、剪枝<a href="#三剪枝" class="hash-link" aria-label="三、剪枝的直接链接" title="三、剪枝的直接链接">​</a></h2>
<p>在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这是就可能因训练样本学得太好了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，我们需要主动去掉一些分支来降低过拟合的风险，而剪枝是决策树学习算法对付过拟合的主要手段。</p>
<p>剪枝分为“预剪枝”和“后剪枝”。预剪枝是指在构造决策树的过程中边构造边剪枝，在决策每个结点之前先估计其对决策树性能的效果，若不能就停止决策该节点并划为叶节点。后剪枝指的是先生成一个决策树，然后从上而下的考察非叶节点并剪枝。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="四示例代码">四、示例代码<a href="#四示例代码" class="hash-link" aria-label="四、示例代码的直接链接" title="四、示例代码的直接链接">​</a></h2>
<ul>
<li><code>from sklearn.tree import DecisionTreeClassifier</code></li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 运行于Jupyter Notebook</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">matplotlib inline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pandas </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> matplotlib</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyplot </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> plt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> seaborn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> sns</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> datasets</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sns</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">set</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#加载鸢尾花的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">iris </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> datasets</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_iris</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">iris</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">columns</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">iris</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">feature_names</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;target&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> iris</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">target</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tmp </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;target&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                   </span><span class="token string" style="color:#e3116c">&quot;target_name&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">iris</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">target_names</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">merge</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">tmp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">on</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;target&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">drop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;target&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sns</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pairplot</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dropna</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">hue</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;target_name&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 训练数据和分类</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">drop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;target_name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_class </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;target_name&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#调用sklearn的决策树方法</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tree </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> DecisionTreeClassifier</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 创建决策树模型</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decision_tree_classifier </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> DecisionTreeClassifier</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 训练决策树</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decision_tree_classifier</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">train_class</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 查看决策树的准确率</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decision_tree_classifier</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">score</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">train_class</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="详解decisiontreeclassifier">详解DecisionTreeClassifier<a href="#详解decisiontreeclassifier" class="hash-link" aria-label="详解DecisionTreeClassifier的直接链接" title="详解DecisionTreeClassifier的直接链接">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">DecisionTreeClassifier</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    criterion</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;gini&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    splitter</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;best&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_depth</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    min_samples_split</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    min_samples_leaf</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    min_weight_fraction_leaf</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_features</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    random_state</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_leaf_nodes</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    min_impurity_decrease</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    min_impurity_split</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    class_weight</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    presort</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="主要参数">主要参数<a href="#主要参数" class="hash-link" aria-label="主要参数的直接链接" title="主要参数的直接链接">​</a></h4>
<ul>
<li>criterion : &#x27;gini&#x27;或者&#x27;entropy&#x27;, 前者是基尼系数，后者是信息熵。两种算法差异不大对准确率无影响，信息墒运算效率低一点，因为它有对数运算.一般说使用默认的基尼系数”gini”就可以了，即CART算法。除非你更喜欢类似ID3, C4.5的最优特征选择方法。</li>
<li>splitter : &#x27;best&#x27; or &#x27;random&#x27;, 前者是在所有特征中找最好的切分点 后者是在部分特征中，默认的”best”适合样本量不大的时候，而如果样本数据量非常大，此时决策树构建推荐”random” .</li>
<li>max_depth : int or None, optional (default=None) 一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。常用来解决过拟合。</li>
<li>min_samples_split : 如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分，如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</li>
<li>min_samples_leaf : 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝，如果样本量不大，不需要管这个值，大些如10W可是尝试下5。</li>
<li>max_features : None（所有），在划分数据集时考虑的最多的特征值数量。</li>
<li>min_weight_fraction_leaf : 这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</li>
<li>max_leaf_nodes : 通过限制最大叶子节点数，可以防止过拟合，默认是&quot;None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制具体的值可以通过交叉验证得到。</li>
<li>min_impurity_decrease : 节点划分最小不纯度。默认值为‘0’；用来限制决策树的增长，如果某节点的不纯度（基尼系数，信息增益，均方差，绝对差）小于这个阈值，则该节点不再生成子节点。</li>
<li>min_impurity_split : 这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值则该节点不再生成子节点。即为叶子节点 。</li>
<li>class_weight : 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重，如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。</li>
<li>presort : bool，默认是False，表示在进行拟合之前，是否预分数据来加快树的构建。对于数据集非常庞大的分类，presort=true将导致整个分类变得缓慢；当数据集较小，且树的深度有限制，presort=true才会加速分类。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="主要属性">主要属性<a href="#主要属性" class="hash-link" aria-label="主要属性的直接链接" title="主要属性的直接  链接">​</a></h4>
<ul>
<li>n_classes_ : 列出类数目</li>
<li>classes_ : 列出类标签</li>
<li>feature_importances_ : 列出每一维特征的重要性</li>
<li>n_features_ : 特征数目</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="主要方法">主要方法<a href="#主要方法" class="hash-link" aria-label="主要方法的直接链接" title="主要方法的直接链接">​</a></h4>
<ul>
<li>fit() : 训练模型</li>
<li>get_params() : 获取参数表的参数</li>
<li>predict() : 返回预测的结果</li>
<li>score() : 返回准确率</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="五回归">五、回归<a href="#五回归" class="hash-link" aria-label="五、回归的直接链接" title="五、回归的直接链接">​</a></h2>
<p>决策树也可以执行回归任务</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tree </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> DecisionTreeRegressor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tree_reg </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> DecisionTreeRegressor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">max_depth</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tree_reg</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">y</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>参数<code>max_depth</code>越大，拟合效果越好，但其值过大时会造成过拟合。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="六决策树的优缺点">六、决策树的优缺点<a href="#六决策树的优缺点" class="hash-link" aria-label="六、决策树的优缺点的直接链接" title="六、决策树的优缺点的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="61-优点">6.1 优点<a href="#61-优点" class="hash-link" aria-label="6.1 优点的直接链接" title="6.1 优点的直接链接">​</a></h3>
<ul>
<li>决策树模型非常直观，生成的一系列“如果……那么……”的逻辑判断很容易让人理解和应用。</li>
<li>决策树搭建和应用的速度比较快，并且可以处理区间型变量和类比型变量。注意，能处理不代表能快速处理。</li>
<li>决策树对数据的分布没有特别严格的要求。</li>
<li>对缺失值很宽容 ，几乎不做任何处理就可以应用。</li>
<li>不容易受数据中极端值（异常值）的影响。</li>
<li>可以同时对付数据中线性和非线性的关系。</li>
<li>可以帮助其他模型算法挑选自变量。</li>
<li>可以准确高效地发现哪些属性对分类最有意义。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="62-缺点">6.2 缺点<a href="#62-缺点" class="hash-link" aria-label="6.2 缺点的直接链接" title="6.2 缺点的直接链接">​</a></h3>
<ul>
<li>决策树原理基于贪心算法，总是局部最优，而不是整体最优。</li>
<li>当目标变量是连续型变量，决策树算法便不再适用，不如使用线性回归算法。</li>
<li>缺乏性能指标和评价方法。</li>
<li>当某些自变量地类别数量比较多，决策树就会增加过拟合地风险。此时需要进行数据转换。</li>
<li>在对区间型自变量进行分箱操作时，可能丧失某些重要的信息。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="七其他">七、其他<a href="#七其他" class="hash-link" aria-label="七、其他的直接链接" title="七、其他的直接链接">​</a></h2>
<p>通过组合多个决策树可以创建随机森林，随机森林可以获得更好的分类结果。sklearn中的相关方法为：</p>
<ul>
<li><code>from sklearn.ensemble import BaggingClassifier</code></li>
<li><code>from sklearn.ensemble import RandomForestRegressor</code>
（第二个是随机森林回归器）</li>
</ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/AI/机器学习/apriori"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">apriori</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/AI/机器学习/朴素贝叶斯"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">朴素贝叶斯</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#一什么是决策树" class="table-of-contents__link toc-highlight">一、什么是决策树</a><ul><li><a href="#相关名词" class="table-of-contents__link toc-highlight">相关名词</a></li><li><a href="#11-决策树简介" class="table-of-contents__link toc-highlight">1.1 决策树简介</a></li><li><a href="#12-优缺点" class="table-of-contents__link toc-highlight">1.2 优缺点</a></li></ul></li><li><a href="#二如何构造一个决策树" class="table-of-contents__link toc-highlight">二、如何构造一个决策树</a></li><li><a href="#三剪枝" class="table-of-contents__link toc-highlight">三、剪枝</a></li><li><a href="#四示例代码" class="table-of-contents__link toc-highlight">四、示例代码</a><ul><li><a href="#详解decisiontreeclassifier" class="table-of-contents__link toc-highlight">详解DecisionTreeClassifier</a></li></ul></li><li><a href="#五回归" class="table-of-contents__link toc-highlight">五、回归</a></li><li><a href="#六决策树的优缺点" class="table-of-contents__link toc-highlight">六、决策树的优缺点</a><ul><li><a href="#61-优点" class="table-of-contents__link toc-highlight">6.1 优点</a></li><li><a href="#62-缺点" class="table-of-contents__link toc-highlight">6.2 缺点</a></li></ul></li><li><a href="#七其他" class="table-of-contents__link toc-highlight">七、其他</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Self-Host</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://rainux.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">Rainux Wiki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://git.rainux.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gitea<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.cnblogs.com/XY-Heruo" target="_blank" rel="noopener noreferrer" class="footer__link-item">博客园<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 花酒锄作田</div></div></div></footer></div>
</body>
</html>